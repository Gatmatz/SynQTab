from synqtab.evaluators.Evaluator import Evaluator
from sdmetrics.single_table.data_augmentation import BinaryClassifierPrecisionEfficacy

class MLAugmentationPrecision(Evaluator):
    """ ML Augmentation Classifier Precision Efficacy Evaluator. Leverages
    https://docs.sdv.dev/sdmetrics/roi-metrics/ml-augmentation/binaryclassifierprecisionefficacy. Parameters:
        - [*required*] `'real_training_data'`: the real data used to train the generator
        - [*required*] `'synthetic_data'`: the synthetic data generated by the generator
        - [*required*] `'real_validation_data'`: the data to use for validation (unseen by the generator)
        - [*required*] `'minority_class_label'`: the label of the minority class
        - [*required*] `'metadata'`: sdmetrics metadata; See 
        https://docs.sdv.dev/sdmetrics/getting-started/metadata/single-table-metadata
        - [*required*] `'prediction_column_name'`: the name of the target column
        - [*optional*] `'notes'`: True/False on whether to include notes in the result or not.
        If absent, defaults to False.
    """
    
    def compute_result(self):
        score = BinaryClassifierPrecisionEfficacy.compute_breakdown(
            real_training_data=self.params.get('real_training_data'),
            synthetic_data=self.params.get('synthetic_data'),
            real_validation_data=self.params.get('real_validation_data'),
            minority_class_label=self.params.get('minority_class_label'),
            metadata=self.params.get('metadata'),
            prediction_column_name=self.params.get('prediction_column_name'),
        )
        if self.params.get('notes', False):
            return score['score'], {
                    "augmented_data": score['augmented_data'],
                    "real_data_baseline": score['real_data_baseline'],
                    "parameters": score['parameters']
            }
        return score['score']
