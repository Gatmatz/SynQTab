from sdmetrics.single_table import DisclosureProtection
from synqtab.evaluators.Evaluator import Evaluator

# Internally computes Categorical CAP as well, so no need for a CAP-specific evaluator

class DisclosureProtectionEvaluator(Evaluator):
    """ Disclosure Protection Evaluator. Leverages
    https://docs.sdv.dev/sdmetrics/data-metrics/privacy/disclosureprotection. Parameters:
        - [*required*] `'real_training_data'`: the real data used to train the generator
        - [*required*] `'synthetic_data'`: the synthetic data generated by the generator
        - [*required*] `'known_column_names'`: the names of the columns that are considered known
        - [*required*] `'sensitive_column_names'`: the names of the columns that are considered sensitive
        - [*optional*] `'notes'`: True/False on whether to include notes in the result or not.
        If absent, defaults to False.
    """

    def compute_result(self):
        score = DisclosureProtection.compute_breakdown(
            real_training_data=self.params.get('real_training_data'),
            synthetic_data=self.params.get('synthetic_data'),
            known_column_names=self.params.get('known_column_names'),
            sensitive_column_names=self.params.get('sensitive_column_names'),
            continuous_column_names=self.params.get('continuous_column_names'),
        )
        if self.params.get('notes', False):
            return score.get('score'), {
                'cap_protection': score.get('cap_protection'),
                'baseline_protection': score.get('baseline_protection')
            }
        return score.get('score')
